{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(\"../../data/cvrp-instances-1.0/train/cvrp-0-pa-train.csv\"), pd.read_csv(\"../../data/cvrp-instances-1.0/dev/cvrp-0-pa-test.csv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 157)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"target\"].copy()\n",
    "X = df.drop([\"target\"], axis=1)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, Y.values.tolist(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_results(grid_search_object, n=5):\n",
    "    cv_results = pd.DataFrame(grid_search_object.cv_results_).sort_values('rank_test_score').head(n)\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_10 = KFold(10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_lambda</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.466783</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.75</td>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>-9256.867318</td>\n",
       "      <td>-4211.444994</td>\n",
       "      <td>-5050.214847</td>\n",
       "      <td>-5393.571883</td>\n",
       "      <td>-10205.732457</td>\n",
       "      <td>-8186.341479</td>\n",
       "      <td>-6151.528556</td>\n",
       "      <td>-6685.599824</td>\n",
       "      <td>1841.493247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.661910</td>\n",
       "      <td>0.074974</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.75</td>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-9017.506743</td>\n",
       "      <td>-4418.538308</td>\n",
       "      <td>-6002.058508</td>\n",
       "      <td>-5218.555536</td>\n",
       "      <td>-9828.893987</td>\n",
       "      <td>-7835.449434</td>\n",
       "      <td>-6221.053920</td>\n",
       "      <td>-6690.856653</td>\n",
       "      <td>1619.868763</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.783914</td>\n",
       "      <td>0.079952</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.75</td>\n",
       "      <td>900</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9420.122244</td>\n",
       "      <td>-4553.596501</td>\n",
       "      <td>-6446.504194</td>\n",
       "      <td>-4909.602740</td>\n",
       "      <td>-9488.667393</td>\n",
       "      <td>-7234.661337</td>\n",
       "      <td>-6358.361002</td>\n",
       "      <td>-6752.015641</td>\n",
       "      <td>1564.199300</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181104</td>\n",
       "      <td>0.038541</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.75</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9565.200160</td>\n",
       "      <td>-4039.590396</td>\n",
       "      <td>-5676.060949</td>\n",
       "      <td>-4997.665171</td>\n",
       "      <td>-9877.887754</td>\n",
       "      <td>-8494.217719</td>\n",
       "      <td>-5818.700718</td>\n",
       "      <td>-6768.190014</td>\n",
       "      <td>1865.464682</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.557069</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.75</td>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9139.527833</td>\n",
       "      <td>-4459.507096</td>\n",
       "      <td>-6359.302834</td>\n",
       "      <td>-4966.901413</td>\n",
       "      <td>-9391.799644</td>\n",
       "      <td>-7817.221063</td>\n",
       "      <td>-6274.540259</td>\n",
       "      <td>-6777.986480</td>\n",
       "      <td>1545.490420</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.272765</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.75</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9484.866748</td>\n",
       "      <td>-4031.667162</td>\n",
       "      <td>-5708.474114</td>\n",
       "      <td>-5324.108557</td>\n",
       "      <td>-10006.538275</td>\n",
       "      <td>-8497.897986</td>\n",
       "      <td>-5602.542230</td>\n",
       "      <td>-6778.634210</td>\n",
       "      <td>1886.759322</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.147951</td>\n",
       "      <td>0.010898</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.75</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-9762.572955</td>\n",
       "      <td>-4135.053584</td>\n",
       "      <td>-5134.456238</td>\n",
       "      <td>-5362.820325</td>\n",
       "      <td>-10386.985647</td>\n",
       "      <td>-8422.502010</td>\n",
       "      <td>-5358.095311</td>\n",
       "      <td>-6791.690918</td>\n",
       "      <td>1990.168720</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093794</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.75</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-9620.211541</td>\n",
       "      <td>-4303.814772</td>\n",
       "      <td>-5056.239187</td>\n",
       "      <td>-5371.147342</td>\n",
       "      <td>-10263.744788</td>\n",
       "      <td>-8584.399816</td>\n",
       "      <td>-5116.730514</td>\n",
       "      <td>-6798.330082</td>\n",
       "      <td>1990.469478</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.982474</td>\n",
       "      <td>0.081143</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.75</td>\n",
       "      <td>800</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9419.225224</td>\n",
       "      <td>-4412.004350</td>\n",
       "      <td>-6571.071472</td>\n",
       "      <td>-4930.922856</td>\n",
       "      <td>-9685.386068</td>\n",
       "      <td>-7278.224776</td>\n",
       "      <td>-6356.128230</td>\n",
       "      <td>-6820.590393</td>\n",
       "      <td>1602.460218</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.351865</td>\n",
       "      <td>0.036044</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.75</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9486.674105</td>\n",
       "      <td>-4615.225895</td>\n",
       "      <td>-6447.475948</td>\n",
       "      <td>-5584.721358</td>\n",
       "      <td>-9954.202976</td>\n",
       "      <td>-7732.010265</td>\n",
       "      <td>-7071.043871</td>\n",
       "      <td>-7027.079811</td>\n",
       "      <td>1578.783586</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "18       0.466783      0.026042         0.002063        0.000066   \n",
       "3        0.661910      0.074974         0.003167        0.002261   \n",
       "16       0.783914      0.079952         0.002382        0.000376   \n",
       "4        0.181104      0.038541         0.002096        0.000502   \n",
       "17       0.557069      0.019469         0.002289        0.000139   \n",
       "6        0.272765      0.024104         0.002104        0.000265   \n",
       "10       0.147951      0.010898         0.001936        0.000116   \n",
       "0        0.093794      0.010241         0.001863        0.000183   \n",
       "5        0.982474      0.081143         0.002907        0.000938   \n",
       "19       0.351865      0.036044         0.001877        0.000476   \n",
       "\n",
       "   param_subsample param_n_estimators param_min_child_weight param_max_depth  \\\n",
       "18            0.75                700                      5              10   \n",
       "3             0.75                700                      5              20   \n",
       "16            0.75                900                      5              20   \n",
       "4             0.75                200                     10              10   \n",
       "17            0.75                700                      5              20   \n",
       "6             0.75                400                     10              10   \n",
       "10            0.75                200                      5              20   \n",
       "0             0.75                200                     10              10   \n",
       "5             0.75                800                      5              10   \n",
       "19            0.75                700                     10              10   \n",
       "\n",
       "   param_learning_rate param_lambda  ... split3_test_score split4_test_score  \\\n",
       "18                0.01           10  ...      -9256.867318      -4211.444994   \n",
       "3                 0.01            1  ...      -9017.506743      -4418.538308   \n",
       "16                0.02            0  ...      -9420.122244      -4553.596501   \n",
       "4                 0.02            0  ...      -9565.200160      -4039.590396   \n",
       "17                0.01            0  ...      -9139.527833      -4459.507096   \n",
       "6                 0.01            0  ...      -9484.866748      -4031.667162   \n",
       "10                0.02            1  ...      -9762.572955      -4135.053584   \n",
       "0                 0.02            1  ...      -9620.211541      -4303.814772   \n",
       "5                 0.02            0  ...      -9419.225224      -4412.004350   \n",
       "19                0.02            0  ...      -9486.674105      -4615.225895   \n",
       "\n",
       "   split5_test_score split6_test_score  split7_test_score  split8_test_score  \\\n",
       "18      -5050.214847      -5393.571883      -10205.732457       -8186.341479   \n",
       "3       -6002.058508      -5218.555536       -9828.893987       -7835.449434   \n",
       "16      -6446.504194      -4909.602740       -9488.667393       -7234.661337   \n",
       "4       -5676.060949      -4997.665171       -9877.887754       -8494.217719   \n",
       "17      -6359.302834      -4966.901413       -9391.799644       -7817.221063   \n",
       "6       -5708.474114      -5324.108557      -10006.538275       -8497.897986   \n",
       "10      -5134.456238      -5362.820325      -10386.985647       -8422.502010   \n",
       "0       -5056.239187      -5371.147342      -10263.744788       -8584.399816   \n",
       "5       -6571.071472      -4930.922856       -9685.386068       -7278.224776   \n",
       "19      -6447.475948      -5584.721358       -9954.202976       -7732.010265   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "18       -6151.528556     -6685.599824     1841.493247                1  \n",
       "3        -6221.053920     -6690.856653     1619.868763                2  \n",
       "16       -6358.361002     -6752.015641     1564.199300                3  \n",
       "4        -5818.700718     -6768.190014     1865.464682                4  \n",
       "17       -6274.540259     -6777.986480     1545.490420                5  \n",
       "6        -5602.542230     -6778.634210     1886.759322                6  \n",
       "10       -5358.095311     -6791.690918     1990.168720                7  \n",
       "0        -5116.730514     -6798.330082     1990.469478                8  \n",
       "5        -6356.128230     -6820.590393     1602.460218                9  \n",
       "19       -7071.043871     -7027.079811     1578.783586               10  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(random_state=42)\n",
    "params = {'n_estimators': [10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900],\n",
    "            'max_depth': [10, 20],\n",
    "            'min_child_weight': [5, 10],\n",
    "            'learning_rate': [0.01, 0.02],\n",
    "            'subsample': [0.75],\n",
    "            'colsample_bytree': [0.2, 0.3],\n",
    "            'alpha': [0, 1, 2],\n",
    "            'lambda': [0, 1, 10],\n",
    "            'gamma': [2, 5, 10]\n",
    "            }\n",
    "xgb_cv = RandomizedSearchCV(xgb, param_distributions=params, scoring='neg_root_mean_squared_error', n_iter=20, cv=cv_10, random_state=42, verbose=1, n_jobs=-1)\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "\n",
    "get_cv_results(xgb_cv, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.75,\n",
       " 'n_estimators': 700,\n",
       " 'min_child_weight': 5,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.01,\n",
       " 'lambda': 10,\n",
       " 'gamma': 5,\n",
       " 'colsample_bytree': 0.3,\n",
       " 'alpha': 2}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(alpha=1, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.3, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=10, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=1, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.3, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=10, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(alpha=1, base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.3, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
       "             gamma=10, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "             min_child_weight=5, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=700, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, ...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(subsample=0.75, n_estimators=700, min_child_weight=5, max_depth=10, learning_rate=0.01, gamma=10, colsample_bytree=0.3, alpha=1, random_state=42, eval_metric=\"rmse\")\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06866218567398531"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mean_absolute_percentage_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
